{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "from commonfunctions import *\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFace(frame):\n",
    "    face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    # face = face_classifier.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40))\n",
    "    face = face_classifier.detectMultiScale(frame, scaleFactor=1.3, minNeighbors=5)\n",
    "    \n",
    "    # Draw a rectangle around the faces (Used for testing purposes)\n",
    "    # for (x, y, w, h) in face:\n",
    "    #     cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
    "    return face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left Pipeline\n",
    "- Gray Conversion\n",
    "- Noise Removal\n",
    "- Edge Detection\n",
    "- Dilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gray Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayConversion(frame):\n",
    "    # conversion of BGR to grayscale is necessary to apply this operation\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen(frame):\n",
    "    # sharpening the image\n",
    "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    sharpened = cv2.filter2D(frame, -1, kernel)\n",
    "    return sharpened\n",
    "\n",
    "    # # gaussian filter\n",
    "    # blur = cv2.GaussianBlur(frame, (5,5), 0)\n",
    "    # # unsharp masking\n",
    "    # sharpened = cv2.addWeighted(frame, 1.5, blur, -0.5, 0)\n",
    "    # return sharpened\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noiseRemoval(frame):\n",
    "    # noise removal using median filter\n",
    "    median = cv2.medianBlur(frame, 11)\n",
    "    # gaussian\n",
    "    blur = cv2.GaussianBlur(median, (3,3), 0)\n",
    "    return blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canny edge detector\n",
    "def cannyDetector(frame):\n",
    "    # canny = cv2.adaptiveThreshold(frame, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    # canny edge detector\n",
    "    canny = cv2.Canny(frame, 150, 190)\n",
    "    return canny \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dilation\n",
    "def dilation(frame):\n",
    "    # dilation\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    dilation = cv2.dilate(frame, kernel, iterations=1)\n",
    "    \n",
    "    return dilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorConversion(frame):\n",
    "    # conversion of GRAY to BGR\n",
    "    BGR = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "    return BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leftPipeline(frame, detectFaceMode = False):\n",
    "    gray        = grayConversion(frame)\n",
    "    denoised    = noiseRemoval(gray)\n",
    "    sharpened   = sharpen(denoised)\n",
    "    canny       = cannyDetector(sharpened)\n",
    "    dilated = canny\n",
    "    if not detectFaceMode:\n",
    "        dilated     = dilation(canny)\n",
    "    # BGR         = colorConversion(dilated)\n",
    "    dilated = 255 - dilated\n",
    "    return dilated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right Pipeline\n",
    "- Separating RGB Channels\n",
    "- Average Filtering\n",
    "- Color Quantization\n",
    "- Combining RGB Channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating RGB channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateRGB(frame):\n",
    "    # separate the RGB channels\n",
    "    b, g, r = cv2.split(frame)\n",
    "    return b, g, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageFilter(b, g, r):\n",
    "    # average filter\n",
    "    b = cv2.blur(b, (5,5))\n",
    "    g = cv2.blur(g, (5,5))\n",
    "    r = cv2.blur(r, (5,5))\n",
    "    return b, g, r"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Quantization\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(b, g, r):\n",
    "    x = 200\n",
    "    y = 180\n",
    "    \n",
    "    # quantize the image\n",
    "    b = np.uint8(b/(x - y))*(x + (y // 2))\n",
    "    g = np.uint8(g/(x - y))*(x + (y // 2))\n",
    "    r = np.uint8(r/(x - y))*(x + (y // 2))\n",
    "\n",
    "    # normalize\n",
    "    b = np.uint8(b/np.max(b)*255)\n",
    "    g = np.uint8(g/np.max(g)*255)\n",
    "    r = np.uint8(r/np.max(r)*255)\n",
    "\n",
    "    return b, g, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KmeansQuantize(b, g, r):\n",
    "    # convert to RGB\n",
    "    # frame_RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Reshape image to an Mx3 array\n",
    "    # img = frame_RGB.reshape(-1,3)\n",
    "    img_b = b.reshape(-1,1)\n",
    "    img_g = g.reshape(-1,1)\n",
    "    img_r = r.reshape(-1,1)\n",
    "\n",
    "    # print(len(np.unique(img, axis=0)), 'unique RGB values out of', img.shape[0], 'pixels')\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    K = 4\n",
    "    compactness_b, labels_b, centers_b = cv2.kmeans(data = img_b.astype(np.float32), K = K, bestLabels = None, criteria = criteria, attempts = 10, flags = cv2.KMEANS_RANDOM_CENTERS)\n",
    "    compactness_g, labels_g, centers_g = cv2.kmeans(data = img_g.astype(np.float32), K = K, bestLabels = None, criteria = criteria, attempts = 10, flags = cv2.KMEANS_RANDOM_CENTERS)\n",
    "    compactness_r, labels_r, centers_r = cv2.kmeans(data = img_r.astype(np.float32), K = K, bestLabels = None, criteria = criteria, attempts = 10, flags = cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    # colours = centers[labels].reshape(-1,3)\n",
    "    colours_b = centers_b[labels_b].reshape(-1,1)\n",
    "    colours_g = centers_g[labels_g].reshape(-1,1)\n",
    "    colours_r = centers_r[labels_r].reshape(-1,1)\n",
    "\n",
    "    # print(len(np.unique(colours, axis=0)), 'unique RGB values out of', colours.shape[0], 'pixels')\n",
    "\n",
    "    img_colours_b = colours_b.reshape(b.shape)\n",
    "    img_colours_g = colours_g.reshape(g.shape)\n",
    "    img_colours_r = colours_r.reshape(r.shape)\n",
    "    \n",
    "    return img_colours_b, img_colours_g, img_colours_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KmeansColorQuantization(combined):\n",
    "    # convert to HSV\n",
    "    combined_HSV = cv2.cvtColor(combined, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    hists = []\n",
    "\n",
    "    # make a histogram for each channel\n",
    "    hist, _ = np.histogram(combined_HSV[:,:,0], bins=np.arange(360+1))\n",
    "    hists.append(hist)\n",
    "    hist, _ = np.histogram(combined_HSV[:,:,1], bins=np.arange(256+1))\n",
    "    hists.append(hist)\n",
    "    hist, _ = np.histogram(combined_HSV[:,:,2], bins=np.arange(256+1))\n",
    "    hists.append(hist)\n",
    "\n",
    "    C = []      # centroids\n",
    "    for h in hists:\n",
    "        C.append(K_histogram(h))\n",
    "\n",
    "    c = combined.shape[-1]\n",
    "    combined_HSV = combined_HSV.reshape((-1,c))\n",
    "    for i in range(c):\n",
    "        channel = combined_HSV[:,i]\n",
    "        # assigns kol rakam lel centroid el a2rab lyh\n",
    "        index = np.argmin(np.abs(channel[:,np.newaxis] - C[i]), axis=1)\n",
    "        combined_HSV[:,i] = C[i][index]\n",
    "    \n",
    "    combined_HSV = combined_HSV.reshape(combined.shape)\n",
    "    combined = cv2.cvtColor(combined_HSV, cv2.COLOR_HSV2BGR)\n",
    "    return combined\n",
    "\n",
    "\n",
    "def update_c(C,hist):\n",
    "    while True:\n",
    "        groups=defaultdict(list)            # kda k2n 3ndna keys, wl values bta3tha empty lists\n",
    "                                            # lama negy actually n3ml key b2a, momkn n-append 3la tool\n",
    "\n",
    "        for i in range(len(hist)):\n",
    "            if(hist[i] == 0):\n",
    "                continue\n",
    "            d=np.abs(C-i)                   # bne7seb el distances y3ny\n",
    "            index=np.argmin(d)              # bnshoof el i a2rab le meen fl C\n",
    "            groups[index].append(i)         # bn7ot el i fl group bta3 el index elly a2rablo\n",
    "\n",
    "        new_C=np.array(C)\n",
    "        for i,indice in groups.items():\n",
    "            if(np.sum(hist[indice])==0):\n",
    "                continue\n",
    "            new_C[i]=int(np.sum(indice*hist[indice])/np.sum(hist[indice]))      # weighted average. dh el centroid el gdeed\n",
    "\n",
    "        if(np.sum(new_C-C)==0):         # kda by7sl convergence\n",
    "            break\n",
    "        C=new_C\n",
    "\n",
    "    return C,groups\n",
    "\n",
    "# Calculates K Means clustering\n",
    "def K_histogram(hist):\n",
    "\n",
    "    alpha=0.001\n",
    "    N=80\n",
    "    C=np.array([128])\n",
    "\n",
    "    while True:\n",
    "        C,groups=update_c(C,hist)\n",
    "        new_C=set()\n",
    "        for i,indices in groups.items():         # i = el lon el bn-map lyh y3ny, indices = list of indices (magmoo3et el alwan elly btroo7 lel i)\n",
    "            if(len(indices)<N):      # lw fy a2al mn 80 lon byroo7o lel lon dh, 5las seebo\n",
    "                new_C.add(C[i])\n",
    "                continue\n",
    "\n",
    "            z, pval=stats.normaltest(hist[indices])          # null hypothesis b2a w ez\n",
    "            # 3ayzeen n3rf el alwan dyh bt-follow el normal distribution wala la\n",
    "            # el alpha dyh el confidence level bta3na\n",
    "            if(pval<alpha):         # kda msh by-follow el normal distribution\n",
    "                left=0 if i==0 else C[i-1]\n",
    "                right=len(hist)-1 if i ==len(C)-1 else C[i+1]\n",
    "                delta=right-left\n",
    "                \n",
    "                if(delta >=3):          # lw el froo2at ma bein el centroids (el alwan) kbeera, deef centroids fl nos temla el fra8at dyh\n",
    "                    c1=(C[i]+left)/2\n",
    "                    c2=(C[i]+right)/2\n",
    "                    new_C.add(c1)\n",
    "                    new_C.add(c2)\n",
    "                else:                   # el far2 msh kbeer, fa 7ot nafs el centroid tany w 5las\n",
    "                    new_C.add(C[i])\n",
    "            else:                       # 7ot el lon zy ma howa lw normal distribution, l2n \n",
    "                new_C.add(C[i])\n",
    "        if(len(new_C)==len(C)):         # y3ny mfeesh ta8yeer kda (mazawedtesh alwan gdeeda)\n",
    "            break\n",
    "        else:\n",
    "            C=np.array(sorted(new_C))\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining RGB Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(b, g, r):\n",
    "    # combine the channels\n",
    "    combined = cv2.merge((b, g, r))\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rightPipeline(frame, detectFaceMode = False):\n",
    "#     b, g, r = separateRGB(frame)\n",
    "#     b, g, r = averageFilter(b, g, r)\n",
    "    \n",
    "#     if detectFaceMode:\n",
    "#         b, g, r = KmeansQuantize(b, g, r)\n",
    "#     else:\n",
    "#         b, g, r = quantize(b, g, r)\n",
    "    \n",
    "#     combined = combine(b, g, r)\n",
    "    \n",
    "#     return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rightPipeline(frame, detectFaceMode = False, videoMode = False, b_old=0, g_old=0, r_old=0, frameCounter=0, skipFrames=1):\n",
    "    b, g, r = separateRGB(frame)\n",
    "    b, g, r = averageFilter(b, g, r)\n",
    "    combined = []\n",
    "    if detectFaceMode:      # face detection\n",
    "        if frameCounter % skipFrames == 0:\n",
    "            b, g, r = KmeansQuantize(b, g, r)\n",
    "            b_old, g_old, r_old = b, g, r\n",
    "        # b, g, r = KmeansQuantize(b, g, r)\n",
    "        combined = combine(b, g, r)\n",
    "    elif videoMode:       # video mode, and not face detection\n",
    "        b, g, r = quantize(b, g, r)\n",
    "        combined = combine(b, g, r)\n",
    "    else:       # picture mode, and not face detection\n",
    "        combined = combine(b, g, r)\n",
    "        combined = KmeansColorQuantization(combined)\n",
    "\n",
    "    \n",
    "    return combined, b_old, g_old, r_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rightPipelineFace(frame):\n",
    "#     b, g, r = separateRGB(frame)\n",
    "#     b, g, r = averageFilter(b, g, r)\n",
    "#     # b, g, r = quantize(b, g, r)\n",
    "#     b, g, r = KmeansQuantize(b, g, r)\n",
    "#     combined = combine(b, g, r)\n",
    "    \n",
    "#     return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the video frame by frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a VideoCapture object to read the video\n",
    "\n",
    "# cap = cv2.VideoCapture('data/Succession-Season-1-1080.mp4')\n",
    "\n",
    "# detectFaceMode = True           # Flag for face detection mode\n",
    "\n",
    "\n",
    "\n",
    "def VideoCartoonizer(detectFaceMode = False):\n",
    "    b_old, g_old, r_old = 0, 0, 0   # initialization for KmeansQuantize\n",
    "    frameCounter = 0                # Counter for face detection mode\n",
    "    skipFrames = 200                 # number of frames to skip before detecting faces again\n",
    "    faces = []                      # List of faces detected in the frame\n",
    "    videos = os.listdir(\"data/Videos/\")\n",
    "    cap = cv2.VideoCapture(\"data/Videos/\" + videos[1])\n",
    "    cap = cv2.VideoCapture(0)  # 0 corresponds to the default camera\n",
    "    try:\n",
    "        # Loop until the end of the video\n",
    "        while (cap.isOpened()):\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:     # If there is no frame to read, i.e. end of video\n",
    "                break\n",
    "\n",
    "            # resize the frame\n",
    "            frame = cv2.resize(frame, (540, 380), fx = 0, fy = 0,\n",
    "                                interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "            leftPipe = leftPipeline(frame, detectFaceMode)          # The left pipeline is applied regardless of the face detection mode\n",
    "\n",
    "            # Check for face detection mode\n",
    "            if detectFaceMode:      # Face detection mode - Cartoonize only the face\n",
    "                # This ensures that regions outside ROI remain unchanged\n",
    "                rightPipe = frame.copy()            \n",
    "                combined = frame.copy()\n",
    "                \n",
    "                faces = detectFace(frame)\n",
    "                # if frameCounter % skipFrames == 0:     # Reset the counter\n",
    "                #     faces = detectFace(frame)\n",
    "                #     frameCounter = 0    \n",
    "\n",
    "                # Loop over the ROI and apply the right pipeline\n",
    "                for face in faces:\n",
    "                    x, y, w, h = face\n",
    "\n",
    "                    # leftPipe[y : y+h, x : x+w] = leftPipeline(frame[y : y+h, x : x+w])\n",
    "                    rightPipe[y : y+h, x : x+w], b_old, g_old, r_old = rightPipeline(frame[y : y+h, x : x+w], detectFaceMode, True, b_old, g_old, r_old, frameCounter, skipFrames)\n",
    "                    # Now, we combine only the ROI of the frame\n",
    "                    combined[y : y+h, x : x+w] = cv2.bitwise_and(rightPipe[y : y+h, x : x+w], rightPipe[y : y+h, x : x+w], mask=leftPipe[y : y+h, x : x+w])\n",
    "                \n",
    "                \n",
    "                frameCounter += 1\n",
    "\n",
    "            else:       # Normal mode - Cartoonize the whole frame\n",
    "                leftPipe = leftPipeline(frame, detectFaceMode)\n",
    "                rightPipe, b_old, g_old, r_old = rightPipeline(frame, detectFaceMode, True, b_old, g_old, r_old, frameCounter, skipFrames)\n",
    "                combined = cv2.bitwise_and(rightPipe, rightPipe, mask=leftPipe)\n",
    "\n",
    "            \n",
    "            cv2.imshow('Frame', frame)                  # Display the original frame\n",
    "            cv2.imshow('left', leftPipe)                # Display the left pipeline result\n",
    "            cv2.imshow('right', rightPipe)              # Display the right pipeline result\n",
    "            cv2.imshow('da5alo f ba3d', combined)       # Display the combined image\n",
    "\n",
    "            \n",
    "            # define q as the exit button\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Throw the exception after releasing the video capture object\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        raise e\n",
    "        # kda msh bn7tag n3ml restart lel kernel m3 kol error\n",
    "    \n",
    "    # release the video capture object\n",
    "    cap.release()\n",
    "    # Closes all the windows currently opened.\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Photo Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(\"data/Photos/\")\n",
    "def TestPhotos(detectFaceMode = False):\n",
    "    b_old, g_old, r_old = 0, 0, 0   # initialization for KmeansQuantize\n",
    "    frameCounter = 0                # Counter for face detection mode\n",
    "    skipFrames = 10                 # number of frames to skip before detecting faces again\n",
    "    cap = cv2.VideoCapture('data/Succession-Season-1-1080.mp4')\n",
    "    path = \"data/Photos/\"\n",
    "    if(detectFaceMode):\n",
    "        path = \"data/faces/\"\n",
    "    for photo in os.listdir(path):\n",
    "        frame = cv2.imread(path+photo, cv2.IMREAD_COLOR)\n",
    "\n",
    "        frame = cv2.resize(frame, (540, 380), fx = 0, fy = 0,\n",
    "                            interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "\n",
    "        \n",
    "        leftPipe = leftPipeline(frame, detectFaceMode)          # The left pipeline is applied regardless of the face detection mode\n",
    "\n",
    "        # Check for face detection mode\n",
    "        if detectFaceMode:      # Face detection mode - Cartoonize only the face\n",
    "            # This ensures that regions outside ROI remain unchanged\n",
    "            rightPipe = frame.copy()            \n",
    "            combined = frame.copy()\n",
    "            \n",
    "            faces = detectFace(frame)\n",
    "            \n",
    "            # Loop over the ROI and apply the right pipeline\n",
    "            for face in faces:\n",
    "                x, y, w, h = face\n",
    "                rightPipe[y : y+h, x : x+w], b_old, g_old, r_old = rightPipeline(frame[y : y+h, x : x+w], detectFaceMode, False, b_old, g_old, r_old, frameCounter, skipFrames)\n",
    "                # Now, we combine only the ROI of the frame\n",
    "                combined[y : y+h, x : x+w] = cv2.bitwise_and(rightPipe[y : y+h, x : x+w], rightPipe[y : y+h, x : x+w], mask=leftPipe[y : y+h, x : x+w])\n",
    "            \n",
    "            frameCounter += 1\n",
    "\n",
    "        else:\n",
    "            leftPipe = leftPipeline(frame, detectFaceMode)\n",
    "            rightPipe, b_old, g_old, r_old = rightPipeline(frame, detectFaceMode, False, b_old, g_old, r_old, frameCounter, skipFrames)\n",
    "            combined = cv2.bitwise_and(rightPipe, rightPipe, mask=leftPipe)\n",
    "        \n",
    "        \n",
    "        # print(\"combined.shape \", combined.shape)\n",
    "        cv2.imshow('Frame', frame)                  # Display the original frame\n",
    "        cv2.imshow('left', leftPipe)                # Display the left pipeline result\n",
    "        cv2.imshow('right', rightPipe)              # Display the right pipeline result\n",
    "        cv2.imshow('da5alo f ba3d', combined)       # Display the combined image\n",
    "\n",
    "        # output=caart(frame)\n",
    "        # # cv2.imwrite(\"cartoon\" + str(i) + \".jpg\", output)\n",
    "        # # convert BGR to RGB\n",
    "        # # output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
    "        # cv2.imshow(\"Cartoon\", output)\n",
    "        \n",
    "        # define q as the exit button\n",
    "        while True:\n",
    "            key = cv2.waitKey(25)\n",
    "            if key & 0xFF == ord('q'):\n",
    "                break\n",
    "            elif key & 0xFF == ord('e'):\n",
    "                # release the video capture object\n",
    "                cap.release()\n",
    "                # Closes all the windows currently opened.\n",
    "                cv2.destroyAllWindows()\n",
    "                # sys.exit()\n",
    "                return\n",
    "    \n",
    "    # release the video capture object\n",
    "    cap.release()\n",
    "    # Closes all the windows currently opened.\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectFaceMode = False\n",
    "# TestPhotos(detectFaceMode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture('data/Succession-Season-1-1080.mp4')\n",
    "# frame = cv2.imread(\"test1.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "# frame = cv2.resize(frame, (540, 380), fx = 0, fy = 0,\n",
    "#                     interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "# # Display the resulting frame\n",
    "# cv2.imshow('Frame', frame)\n",
    "\n",
    "# # conversion of BGR to grayscale is necessary to apply this operation\n",
    "# leftPipe = leftPipeline(frame)          # The left pipeline is applied regardless of the face detection mode\n",
    "\n",
    "# # Check for face detection mode\n",
    "# if detectFaceMode:      # Face detection mode - Cartoonize only the face\n",
    "#     # This ensures that regions outside ROI remain unchanged\n",
    "#     rightPipe = frame.copy()            \n",
    "#     combined = frame.copy()\n",
    "    \n",
    "#     faces = detectFace(frame)\n",
    "    \n",
    "#     # Loop over the ROI and apply the right pipeline\n",
    "#     for face in faces:\n",
    "#         x, y, w, h = face\n",
    "#         rightPipe[y : y+h, x : x+w] = rightPipeline(frame[y : y+h, x : x+w])\n",
    "#         # Now, we combine only the ROI of the frame\n",
    "#         combined[y : y+h, x : x+w] = cv2.bitwise_and(rightPipe[y : y+h, x : x+w], rightPipe[y : y+h, x : x+w], mask=leftPipe[y : y+h, x : x+w])\n",
    "\n",
    "# else:\n",
    "#     leftPipe = leftPipeline(frame)\n",
    "#     rightPipe = rightPipeline(frame)\n",
    "#     combined = cv2.bitwise_and(rightPipe, rightPipe, mask=leftPipe)\n",
    "\n",
    "\n",
    "# cv2.imshow('Frame', frame)                  # Display the original frame\n",
    "# cv2.imshow('left', leftPipe)                # Display the left pipeline result\n",
    "# cv2.imshow('right', rightPipe)              # Display the right pipeline result\n",
    "# cv2.imshow('da5alo f ba3d', combined)       # Display the combined image\n",
    "\n",
    "# # define q as the exit button\n",
    "# while True:\n",
    "#     key = cv2.waitKey(25)\n",
    "#     if key & 0xFF == ord('q'):\n",
    "#         break\n",
    "#     elif key & 0xFF == ord('e'):\n",
    "#         # release the video capture object\n",
    "#         cap.release()\n",
    "#         # Closes all the windows currently opened.\n",
    "#         cv2.destroyAllWindows()\n",
    "#         sys.exit()\n",
    "#         # return\n",
    "\n",
    "# # release the video capture object\n",
    "# cap.release()\n",
    "# # Closes all the windows currently opened.\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MyGUI at 0x1d21e604700>"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyGUI:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.main_window = tk.Tk()\n",
    "        self.main_window.geometry('500x300')\n",
    "        self.main_window.title('Cartoonizer')\n",
    "        \n",
    "        img = ImageTk.PhotoImage(Image.open(\"BackGS.png\"))\n",
    "        self.panel = tk.Label(image = img)\n",
    "        self.panel.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "        self.check_state = tk.IntVar()\n",
    "        \n",
    "        # write welcome at top of screen\n",
    "        \n",
    "        self.welcome_label = tk.Label(self.main_window, text='Welcome to our Cartoonizer', font=('Callibri', 25 ), bg='#000836', fg='white')\n",
    "        self.welcome_label.pack(side='top')\n",
    "        \n",
    "        \n",
    "        self.check_state = tk.IntVar()\n",
    "        \n",
    "        self.cartoonize_option = tk.Checkbutton(self.main_window, text='Cartoonize Face Only',font=('Callibri', 16 ), variable=self.check_state, onvalue=1, offvalue=0)    \n",
    "        self.cartoonize_option.configure(bg='pink')\n",
    "        self.cartoonize_option.configure(fg='#000836')\n",
    "        self.cartoonize_option.configure(activebackground='#ffcdd6')\n",
    "        self.cartoonize_option.pack(side='top', pady=25)\n",
    "        \n",
    "        self.start_cartoonize_button = tk.Button(self.main_window, text='Start Photo Cartoonization', command=self.get_cartoonize_option)\n",
    "        self.start_cartoonize_button.configure(bg='pink')\n",
    "        self.start_cartoonize_button.configure(fg='#000836')\n",
    "        self.start_cartoonize_button.pack(pady=10)\n",
    "\n",
    "        self.start_cartoonize_button_video = tk.Button(self.main_window, text='Start Video Cartoonization', command=self.get_cartoonize_option_video)\n",
    "        self.start_cartoonize_button_video.configure(bg='pink')\n",
    "        self.start_cartoonize_button_video.configure(fg='#000836')\n",
    "        self.start_cartoonize_button_video.pack(pady=10)\n",
    "        \n",
    "        self.quit_button = tk.Button(self.main_window, text='Quit', command=self.main_window.destroy)\n",
    "        \n",
    "        self.quit_button.configure(bg='pink')\n",
    "        self.quit_button.configure(fg='#000836')\n",
    "        self.quit_button.pack(side='bottom', pady=10)\n",
    "\n",
    "        \n",
    "        self.main_window.mainloop()\n",
    "        \n",
    "    def get_cartoonize_option(self):\n",
    "        \n",
    "        TestPhotos(self.check_state.get())\n",
    "    \n",
    "    def get_cartoonize_option_video(self):\n",
    "        \n",
    "        VideoCartoonizer(self.check_state.get())\n",
    "    \n",
    "        \n",
    "MyGUI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_c(C,hist):\n",
    "#     while True:\n",
    "#         groups=defaultdict(list)\n",
    "\n",
    "#         for i in range(len(hist)):\n",
    "#             if(hist[i] == 0):\n",
    "#                 continue\n",
    "#             d=np.abs(C-i)\n",
    "#             index=np.argmin(d)\n",
    "#             groups[index].append(i)\n",
    "\n",
    "#         new_C=np.array(C)\n",
    "#         for i,indice in groups.items():\n",
    "#             if(np.sum(hist[indice])==0):\n",
    "#                 continue\n",
    "#             new_C[i]=int(np.sum(indice*hist[indice])/np.sum(hist[indice]))\n",
    "\n",
    "#         if(np.sum(new_C-C)==0):\n",
    "#             break\n",
    "#         C=new_C\n",
    "\n",
    "#     return C,groups\n",
    "\n",
    "# # Calculates K Means clustering\n",
    "# def K_histogram(hist):\n",
    "\n",
    "#     alpha=0.001\n",
    "#     N=80\n",
    "#     C=np.array([128])\n",
    "\n",
    "#     while True:\n",
    "#         C,groups=update_c(C,hist)\n",
    "\n",
    "#         new_C=set()\n",
    "#         for i,indice in groups.items():\n",
    "#             if(len(indice)<N):\n",
    "#                 new_C.add(C[i])\n",
    "#                 continue\n",
    "\n",
    "#             z, pval=stats.normaltest(hist[indice])\n",
    "#             if(pval<alpha):\n",
    "#                 left=0 if i==0 else C[i-1]\n",
    "#                 right=len(hist)-1 if i ==len(C)-1 else C[i+1]\n",
    "#                 delta=right-left\n",
    "#                 if(delta >=3):\n",
    "#                     c1=(C[i]+left)/2\n",
    "#                     c2=(C[i]+right)/2\n",
    "#                     new_C.add(c1)\n",
    "#                     new_C.add(c2)\n",
    "#                 else:\n",
    "#                     new_C.add(C[i])\n",
    "#             else:\n",
    "#                 new_C.add(C[i])\n",
    "#         if(len(new_C)==len(C)):\n",
    "#             break\n",
    "#         else:\n",
    "#             C=np.array(sorted(new_C))\n",
    "#     return C\n",
    "\n",
    "# # The main controlling function\n",
    "# def caart(img):\n",
    "\n",
    "#     kernel=np.ones((2,2), np.uint8)\n",
    "#     output=np.array(img)\n",
    "#     x,y,c=output.shape\n",
    "#     for i in range(c):\n",
    "#         output[:,:,i]=cv2.bilateralFilter(output[:,:,i],5,150,150)\n",
    "\n",
    "#     edge=cv2.Canny(output, 100, 200)\n",
    "#     output=cv2.cvtColor(output,cv2.COLOR_RGB2HSV)\n",
    "\n",
    "#     hists = []\n",
    "\n",
    "#     hist,_=np.histogram(output[:,:,0],bins =np.arange(180+1))\n",
    "#     hists.append(hist)\n",
    "#     hist,_=np.histogram(output[:,:,1],bins =np.arange(256+1))\n",
    "#     hists.append(hist)\n",
    "#     hist,_=np.histogram(output[:,:,2],bins =np.arange(256+1))\n",
    "#     hists.append(hist)\n",
    "\n",
    "\n",
    "#     C=[]\n",
    "#     for h in hists:\n",
    "#         C.append(K_histogram(h))\n",
    "#     #print(\"centroids: {0}\".format(C))\n",
    "\n",
    "#     output=output.reshape((-1,c))\n",
    "#     for i in range(c):\n",
    "#         channel=output[:,i]\n",
    "#         index=np.argmin(np.abs(channel[:, np.newaxis] - C[i]), axis=1)\n",
    "#         output[:,i]=C[i][index]\n",
    "#     output=output.reshape((x,y,c))\n",
    "#     output=cv2.cvtColor(output, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "#     contours,_=cv2.findContours(edge,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "#     cv2.drawContours(output,contours,-1,0,thickness=1)\n",
    "#     #cartoon = cv2.bitwise_and(output, output, mask=contours)\n",
    "#     for i in range(3):\n",
    "#         output[:,:,i]=cv2.erode(output[:,:,i], kernel, iterations=1)\n",
    "#     #Laplacian = cv2.Laplacian(output,cv2.CV_8U, ksize=11)\n",
    "#     #output=output-Laplacian\n",
    "#     return output\n",
    "\n",
    "        \n",
    "# # photos = os.listdir(\"data/Photos/\")\n",
    "# # images = []\n",
    "# # for i, photo in enumerate(photos):\n",
    "# #     print(i, photo, )\n",
    "# #     output=caart(cv2.imread(\"data/Photos/\" + photo))\n",
    "# #     # cv2.imwrite(\"cartoon\" + str(i) + \".jpg\", output)\n",
    "# #     # convert BGR to RGB\n",
    "# #     output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
    "# #     images.append(output)\n",
    "# #     print(\"output.shape \", output.shape)\n",
    "# #     # io.imshow(output)\n",
    "# # show_images([*images])\n",
    "\n",
    "\n",
    "# # cv2.imshow('testing', images[0])\n",
    "\n",
    "# # output=caart(cv2.imread(\"data/Photos/\" + photos[1]))\n",
    "# # # cv2.imwrite(\"cartoon.jpg\", output)\n",
    "# # # convert BGR to RGB\n",
    "# # output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
    "# # io.imshow(output)\n",
    "# # # cv2.imshow('Frame', output)                  # Display the original frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TestPhotos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
